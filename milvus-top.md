# milvus 设计方案
- 使用共享存储，计算与存储分离
- `ES` 的 `replica` 是做 `HA` 的，这里的 `replica` 是做 `QPS` 的
- 支持粗粒度的`多写`操作
  - 一个 `client` 只有一个写节点。不存在把一次写操作的数据分成多份，然后多个写节点同时写的情况
  - 如果需要提高写入速度，可以链接多个 `client`
- 每次插入均生成一个新的文件，不是在旧文件上的追加
- 每次合并也会生成一个新的文件，原文件并不直接删除，而是由后台程序安全的删除
- 每次删除均生成一个新的 `delete log` 文件

## 前提假设
- 同一个客户端严格保操作时序，不同客户端不保证时序
    - C<sub>1</sub> 在本地时刻 T<sub>0</sub> 发起插入操作 I<sub>0</sub>，插入数据 D<sub>A</sub>，并执行 `flush` 操作
    - C<sub>1</sub> 在本地时刻T<sub>1</sub> 发起查询操作 Q<sub>1</sub>，数据 D<sub>A</sub>一定对Q<sub>1</sub>可见
    - C<sub>2</sub> 在本地时刻T<sub>2</sub>时刻发起查询操作 Q<sub>2</sub>，数据 D<sub>A</sub>不保证对Q<sub>2</sub>可见
    - 因为 I<sub>0</sub> 与 Q<sub>1</sub> 都是由 C<sub>1</sub> 发起，I<sub>0</sub> 与 Q<sub>1</sub>属于同步操作，所以 Q<sub>1</sub> 命令到达服务端时，I<sub>0</sub>操作已经完成 ，所以D<sub>A</sub>一定对Q<sub>1</sub>可见
    - Q<sub>2</sub> 和  I<sub>0</sub> 属于不同客户端发起的操作,所以不能保证 Q<sub>2</sub> 达到服务器后， I<sub>0</sub> 操作已经完成，数据 D<sub>A</sub>不保证对Q<sub>2</sub>可见
    - 如果 C<sub>1</sub> 和 C<sub>2</sub> 是由同一个用户发起的的链接，并且用户确保 I<sub>0</sub> 操作返回之后，再发起 Q<sub>2</sub> 操作，那么数据 D<sub>A</sub>保证对Q<sub>2</sub>可见
- 未 `flush` 之前，数据对所有客户端均不可见，`flush` 之后数据对所有客户端可见
  - C<sub>1</sub> 在本地时刻 T<sub>0</sub> 发起插入操作 I<sub>0</sub>，插入数据 D<sub>A</sub>，未执行 `flush` 操作
  - C<sub>1</sub> 在本地时刻 T<sub>1</sub> 发起查询操作 Q<sub>1</sub>，数据 D<sub>A</sub>对Q<sub>1</sub>不可见
  - C<sub>1</sub> 在本地时刻 T<sub>2</sub> 发起 `flush` 操作
  - C<sub>1</sub> 在本地时刻 T<sub>3</sub> 发起查询操作 Q<sub>3</sub>，数据 D<sub>A</sub>对Q<sub>3</sub>可见
- 未 `flush` 的操作在客户端断开后均被抛弃
  - C<sub>1</sub> 在本地时刻 T<sub>0</sub> 发起插入操作 I<sub>0</sub>，插入数据 D<sub>A</sub>，未执行 `flush` 操作
  - C<sub>1</sub> 在本地时刻 T<sub>1</sub> 发起删除操作 D<sub>1</sub>，删除数据 D<sub>B</sub>，未执行 `flush` 操作
  - C<sub>1</sub> 在本地时刻 T<sub>2</sub> 与服务端断开链接
  - 数据 D<sub>A</sub> 在服务器端被抛弃，数据 D<sub>B</sub>在服务端未被删除，依然可以被查询到
- `Insert` 和 `Delete` 操作需要 `flush`，其它不需要,如`create table`,`drop table`
- 这个设计针对批插入，并且删除属于低频操作
- 不涉及用户管理，及访问控制，访问控制由 `IP` 地址白名单实现

---

## 配置文件
- `auto_flush`:
  - 类型 : `bool`
  - 默认值 : `false`
  - 无论是否设置 `auto_flush` , `milvus` 程序保证 `flush` 间的数据要么整体成功，要么整体失败
  - 当 `auto_flush` 为 `false` 时，`client` 端需要手动调用 `flush`
  - 当 `auto_flush` 为 `true` 时，以下两种情况均可以触发 `flush`
    - 定时超过 `flush_interval` 后触发
    - 插入的数据超过 `flush_limitition` 后触发
  - 当 `auto_flush` 为 `true` 时，如果自动触发的 `flush` 操作运行失败，则数据丢失，不向用户返回任何信息，仅仅记录日志 
- `flush_interval`
  - 类型 : `int32`
  - 默认值 ： `1000`
  - 定时触发 `flush` 的时间间隔，单位为毫秒
- `flush_limitition`
  - 类型 : `string`
  - 默认值 : `16M`
  - 插入的数据超过 `flush_limitition` 后触发 `flush` 操作
- `num_replicas`:
  - 类型 : `int32`
  - 默认值 : `0`
  - 数据在不同节点间备份的数目,`0` 表示数据没有备份
  - 数据只能在不同的节点间备份，因此该值的上限为 `num_nodes-1`
- `num_nodes`:
  - 类型 : `int32`
  - 默认值 : `1`
  - 负责数据插入及查询节点的数目
- `master_address`: 
  - 无默认值
  - `Master` 节点的 `ip` 地址和端口
- `node_address_lists`:
  - 无默认值
  - 这是个列表，包含每个记录包含一下信息
    - `node` 节点编号,从 `0` 开始
    - `IP` 地址
    - 端口
- `high_water_level`:
  - 类型 : `double`
  - 默认值 : `0.6`
  - 取值范围为 `[0 1]` 当 `Milvus` 节点内存使用率达到 `hight_water_level` 后，表示当前节点已经没有富余内存，此时向节点插入数据会别转发到其他节点上
- `master_heart_beat_interval`:
  - 类型 : `int32`
  - 默认值 : `1000`
  - `Master` 节点向 `Milvus` 节点发送心跳信号请求的时间间隔
- `time_out_on_heart_beat`:
  - 类型 : `int32`
  - 默认值 ： `3`
  - 连续 `time_out_on_heart_beat` 次心跳信号返回超时，则认为对应的 `Milvus` 节点宕机
  - 在 `k8s` 环境中， 因为 `k8s` 可以帮助重启节点，所以该值可以设的比较大，因为认为失效的这段时间内，`Milvus` 节点可能正在重启过程中

---

  
## 整体框图
```txt
+------------------------------------------+ +------------------------------------------+
|               Milvus-Cluster             | |               Milvus-Cluster             |
|  +------------------------------------+  | |  +------------------------------------+  |
|  |             Master                 |  | |  |             Master                 |  |
|  +------------------------------------+  | |  +------------------------------------+  |
|                                          | |                                          |
|  +----------+ +----------+ +----------+  | |  +----------+ +----------+ +----------+  |
|  |  Milvus  | |  Milvus  | |  Milvus  |  | |  |  Milvus  | |  Milvus  | |  Milvus  |  |
|  +----------+ +----------+ +----------+  | |  +----------+ +----------+ +----------+  |
|                                          | |                                          |
+------------------------------------------+ +------------------------------------------+

+---------------------------------------------------------------------------------------+
|                                       S3,etcd                                         |
+---------------------------------------------------------------------------------------+
```
- `Milvus-Cluster` 包含多个 `Miluvs` 节点
- `Milvus-Cluster` 有一个全局唯一的`ID`
- 底层存储不一定是 `S3`，只要是共享存储即可， `etcd` 中 `<S3_file_path>` 改为对应的共享存储路径即可

---

## `Milvus` 框图
- 每个 `Milvus` 节点都包含完整的 `meta` 信息，能够知道当前查询指令包含几个文件，这些文件分别有几个 `replica` 以及分布在哪些 `Milvus` 节点上
- 每个 `Milvus` 节点有唯一的编号，从 `1` 开始
- 对外提供查询服务，获得 `Milvus` 节点正在执行的任务信息，包括
  - 查询操作
  - 插入操作
  - 二级查询操作
  - 复制操作， 包含数据源，文件名，etcd中的 `key` 和 `revision`
  - 创建索引操作
- 对外提供查询服务，指定的文件名是否在 `Milvus` 节点内，返回内容包括:
  - 文件名
  - 文件是否在节点的内存中
  - 文件是否在节点的磁盘中
- 定时任务
  - 根据 `meta` 定时检查是否存在与本节点相关的复制任务
    - 如果有复制任务，则从 `S3` 复制文件
    - 因为 `复制操作` 为 `幂等` 行为，所以重复执行不影响最终结果

---

## `Master` 节点
- `Master` 是无状态的服务
- `Master` 根据负载状态告知 `client` 链接哪个 `Milvus` 节点
  - `client` 首先链接 `Master`,`Master`根据各个`Miluvs`节点的负载状态，选择一个合适的 `Miluvs`节点，并其 `IP` 地址和端口返回给 `client`
  - `client` 收到 `Master` 返回的 `Miluvs` 节点 `IP`地址和端口后，主动断开和 `Master` 的链接
  - `client` 链接目标的 `Milvus` 节点
  - 因此 `Milus-Cluster` 内的所有 `Milvus` 节点和 `Master` 节点都必须对外暴露自己的IP地址
```txt
              client 链接 Milvus 节点

+--------+                                   +--------+
|        |                                   |        |
|        | (1) Connect with Master           |        |
|        |----------------------------------->        |
|        |                                   |        |
|        | (2) Milvus node IP and Port       |        |
|        <-----------------------------------| Master |
|        |                                   |        |
|        | (3) Close connection with Master  |        |
| client <----------------X----------------->|        |
|        |                                   |        |
|        |                                   |        |
|        |                                   |        |
|        |                                   +--------+
|        |
|        |
|        |                                   +--------+
|        | (4) Connect with Milvus           |        |
|        |-----------------------------------> Milvus |
|        |                                   |        |
+--------+                                   +--------+
```

- `Master` 定期的向所有的 `milvus` 节点请求心跳信号，确定 `milvus` 节点是否依然存活
- `Milvus` 节点可以向 `Master` 节点请求其他节点的负载状态；该功能在 `Reduce`模式的插入操作中使用，如果当前`Milvus`节点的内存超过警戒线，则`Milvus` 节点向 `Master` 节点请求其它`Miluvs`节点的负载状态，然后选择一个选择一个低负载的节点，将插入数据转发到那个节点
- `Master` 需要 `watch etcd` 的 这个 `/<user_name>/config/<Milvus-Cluster_ID>`，当有新的节点加入后会更新这个 `key`

---

## `etcd` 及元数据
- `etcd` 保存全局的 `meta` 信息
- 多个 `Milvus-Cluster` 可以共用一个 `etcd`
- `etcd` 中的 `meta` 类型
  - 用户列表
    - `key` 为 `/user_list`
    - `value` 为一个 `array`，每条记录包含一个`<user_name>`
  - `key` 对应 `S3` 的数据文件
    - `key` 的命名格式为: `/<user_name>/<collection_name>/data/<S3_file_path>`
    - `value` 内容包含
      - 文件类型：索引文件，原始向量文件，标量文件,`delete log`
      - 文件大小，单位为字节
      - `replicas`： 插入该文件及拥有该文件 `replica` 的 `Milvus` 节点序号
        - 负责插入文件的节点称为 `InsertNode`
        - 其它拥有该文件 `replica` 的节点称为 `ReplicaNode`
        - 这是个 `array`，第一个元素为 插入该文件的节点序号，后续为拥有该文件 `replica` 的节点序号
        - 假设该文件由节点`2`插入，并且节点 `1` 和 节点 `5` 都拥有该文件的 `replica`，这这个值为 `[2,1,5]`; 该文件的 `InsertNode` 为节点`2`, `ReplicaNode` 为 节点`1`、节点`5` 
        - 假设该文件由节点`2`插入，并且节点 `1` 和 节点 `5` 都拥有该文件的 `replica`，但是节点`1` 正在复制这个文件，并未完成，而节点`5` 已经完成复制，此时这个值为 `[2,-1,5]`
      - 如果为标量文件，还需记录以下内容
        - 对应的列名
        - 当前标量文件对应的向量文件名
      - 如果为索引文件，则需要记录所对应的原始向量文件列表，索引文件可以由多个向量文件构成
  - `key` 对应属于当前用户的 `collection list`
    - `key` 命名格式为：`/<user_name>/collection_list`
    - `value` 为一个 `array`,每条记录的格式为: `<collection_name> : <create_time>, <index_type>` 按照 `<create_time>` 降序排列
  - `key` 对应属于当前用户的 `Milvus-Cluster` 属性，一个用户可以拥有多个 `Milvus-Cluster`
    - `key` 命名格式为：`/<user_name>/config/<Milvus-Cluster_ID>`
    - `value` 内容为 `json` 格式存储的 `Milvus-Cluster` 配置文件

---

## 查询流程

```txt
                             查询流程

+--------+                             +---------+                             +---------+
| client |                             |  N1     |                             |  etcd   |
|        |     (1) Query q1            |         |  (2) request meta of T0     |         |
|        |----------------------------->         |----------------------------->         |
|        |                             |         |                             |         |
|        |                             | (F1 F2) |  (3) meta of T0             |         |
|        |                             |         <-----------------------------|         |
|        |                             |         |                             +---------+
|        |                             |         |  (4) q11 on F1
|        |                             |         |------------------+
|        |                             |         |                  |
|        |                             |         <------------------+
|        |                             |         |                              +---------+
|        |                             |         |  (4) q12 on F0               |   N2    |
|        |                             |         |------------------------------>         |
|        |                             |         |                              | (F0 F1) |
|        |                             |         |                              +---------+
|        |  (6) Response of q1         |         |
|        <-----------------------------|         |                              +---------+
|        |                             |         |  (4) q13 on F2               |   N3    |
|        |                             |         |------------------------------>         |
|        |                             |         |                              | (F0 F2) |
|        |                             |         |                              +---------+
|        |                             |         |  (5) reduce on q11 q12 q13
|        |                             |         |----------------------------+
|        |                             |         |                            |
|        |                             |         <----------------------------+
|        |                             |         |
+--------+                             +---------+
```

- `Milvus` 节点 `N1` 收到针对 `collection` `T0` 的查询指令 `q1`
- `N1` 从 `etcd` 获得当前的 `revision` 值 `r1`
- `N1` 提取 `T0` 在 `r1` 下的所有 `meta` 信息
- 根据 `meta` 信息，`N1` 得到这些信息
  - `T0` 一共包含 `3` 个文件：`F0,F1,F2`
  - `F0` 位于 `N2 N3` 节点
  - `F1` 位于 `N1 N2` 节点
  - `F2` 位于 `N1 N3` 节点
- `N1` 向 `N1, N2, N3` 发送请求，获得节点当时的负载状态, 据此，`N1` 做出如下安排:
  - 向 `N1` 发送查询请求 `q11`，明确要求在文件 `F1` 上执行 `q1` 查询
  - 向 `N2` 发送查询请求 `q12`，明确要求在文件 `F0` 上执行 `q1` 查询
  - 向 `N3` 发送查询请求 `q13`，明确要求在文件 `F2` 上执行 `q1` 查询
- `N1` 收到 `q11 q12 q13` 结果后，执行 `reduce` 操作
- `N1` 向客户端发送查询过结果


**异常处理**
- 查询过程中，如果 `N1` 宕机，如何处理？
  - 因为 `client` 值直接与 `N1` 链接的
  - 那么 `client` 可以感知到与 `N1` 的链接断开，直接返回本次查询失败
- 查询过程中, 如果 `N2` 宕机，如何处理？
  - `N2` 宕机，`N1` 可以感知到 `q12` 查询失败
  -  根据 `meta` 可以知道 `q12` 负责的数据 `F0` 在 `N3` 上存在 `replica`
  - 向 `N3` 发送查询请求 `q14`，明确要求在文件 `F0` 上执行 `q1` 查询
- 如果 `N2 N3` 都宕机，那么 `N1` 无法获得本次查询需要的所有数据，直接放回查询失败，在 `N2 N3` 节点启动前，服务不可用
- `q11 q12 q13` 必须设置超时机制
- `meta` 信息显示 `F0` 正在往 `N2` 复制，此时如何处理？
  - 针对 `F0` 的查询在节点 `N3` 上执行
  - 向 `N2` 发送复制指令，指示 `N2` 从 `S3` 复制 `F0`，这个复制指令与当前查询无任何关联
- `meta` 信息显示 `F0` 正在往 `N2` 复制，但是 `N3` 已经宕机，如何处理?
  - 向 `N2` 发送查询指令，观察 `N2` 是否正在执行复制任务
  - 如果 `N2` 正在执行复制任务任务，且数据源为 `S3`，则 `N1` 等待 `N2` 复制完成后在执行
  - 如果 `N2` 的任务列表内没有复制任务，则 `N1` 向 `N2` 发送复制任务，指示 `N2` 从 `S3` 复制 `F0` ， 等待复制完成后在执行查询 

---


## 数据两阶段插入流程

```txt
                                     两阶段插入

+--------+                                   +--------+
|        |                                   |        |                                 +------+
|        |         (1) Insert(vector)        |        |      (3) Put("tmp-s3")          |      |
|        |----------------------------------->        |--------------------------------->  S3  |
|        |                                   |        |                                 |      |
|        |         (2) Flush                 |        |                                 +------+
|        |----------------------------------->        |
|        |                                   |        |
|        |         (4) "tmp-etcd"            |        |                                 +------+
| client <-----------------------------------| Milvus |      (6) Put("tmp-etcd")        |      |
|        |                                   |        |---------------------------------> etcd |
|        |         (5) "tmp-etcd"            |        |                                 |      |
|        |----------------------------------->        |                                 +------+
|        |                                   |        |
|        |         (7) Success               |        |
|        <-----------------------------------|        |
|        |                                   |        |
|        |                                   |        |
+--------+                                   +--------+
```

- `client` 执行 `flush` 操作触发数据写 `S3`
- `Milvus` 节点将数据 `put` 到 `S3`，假设文件名为 `tmp-s3`
- 获得 `tmp-s3` 对应 `etcd` 中的 `key`，假设为 `tmp-etcd`
- 向 `client` 发送 `tmp-etcd` 字符串
- `client` 向 `milvus` 返回 `tmp-etcd` 字符串确认收到
- `milvus` 收到 `client`的返回后，再 `etcd` 插入 `tmp-etcd` -> `tmp-s3`
- 向 `client` 发送 `flush` 操作成功
- 如果 `Milvus` 超时未收到 `client` 的返回，则删除 `tmp-s3` 文件，切直接切断当前与 `client` 的链接

**注意事项**
`client`有下列`3`种状态
- `client` 收到 `flush` 操作成功或失败
- `client` 未收到任何信息，直接超时，表示当前操作失败
- `client` 收到 `tmp-etcd` 信息，当时未收到 `flush` 操作成功的信息，此时 `client` 需要重新链接并向 `milvus` 查询 `tmp-etcd` 是否在 `etcd` 中

如果 `tmp-etcd` 对应的 `tmp-s3` 文件被合并导致 `tmp-etcd` 不存在，可能导致 `client` 重新链接时查询 `tmp-etcd` 失败；为了防止这种情况出现，文件合并后，需要在某个地方依然保存 `tmp-etcd`， 确保可以被查询到

---

## 插入流程
```txt
                                   插入流程

+--------+                         +--------+
| client |                         |  N1    |                                 +------+
|        |   (1) Insert(F0)        |        |      (2) Put(F0)                |      |
|        |------------------------->        |--------------------------------->  S3  |
|        |                         |        |                                 |      |
|        |                         |        |                                 +------+
|        |                         |        |
|        |                         |        |                                 +-------------+
|        |                         |        |      (3) Query State            |             |
|        |                         |        |---------------------------------> N2 N3 N4 N5 |
|        |                         |        |                                 |             |
|        |  (5) Insert Success     |        |                                 +-------------+
|        <-------------------------|        |
|        |                         |        |                                 +------+
|        |                         |        |     (4) Put meta of F0          |      |
|        |                         |        |---------------------------------> etcd |
|        |                         |        |    replicas: [1, -3,-5]         |      |
|        |                         |        |                                 +------+
|        |                         |        |
|        |                         |        |                                 +-------+
|        |                         |        |     (6) Copy F0 from N1 or S3   |       |
|        |                         |        |---------------------------------> N3 N5 |
|        |                         |        |                                 |       |
|        |                         |        |                                 +-------+
+--------+                         +--------+
```

- `client` 向 `Milvus` 节点 `N1` 插入数据，生成文件 `F0`
- `N1` 将文件 `F0` 写入 `S3`
- `N1` 向其它节点 `N2 ~ N5` 发送查询请求，询问其负载状态
- 根据 `N2 ~ N5` 的负载状态，及配置文件中 `num_replicas`，`N1` 决定将 `F0` 分别复制到 `N3` 和 `N5`
- 向 `etcd` 中插入 `meta` 信息，其中 `replicas` 值为 `[1,-3,-5]`；`-3 -5` 表明数据 `F0` 正在往 `N3 N5` 复制的过程中
- 向 `client` 返回结果，表明插入成功
- 向 `N3 N5` 发送复制指令，将文件 `F0` 从 `N1` 节点复制到 `N3 N5` 节点



**注意事项**
- 采用批处理模式，保证 `flush` 内的操作整理成功或整体失败，不存在 `F0` 部分数据插入成功，部分数据插入失败
- 如果 `N1` 已经向 `client`返回插入成功，但是还未向 `N2` 和 `N5` 发送复制指令，此时 `N1` 宕机了，如何处理？
  - `N1` 节点内的定时任务可以启动复制操作
  - 如果某次查询用到了 `F0` 数据，查询指令也可以启动复制任务
- 插入请求中包含当前插入的数据量，以 `Byte` 计算

---

## 插入转发
- `client` 向 `Milvus` 节点 `N1` 插入数据 `F0`
- `N1` 发现自身没有富余的内存用于存放 `F0`
- `N1` 向其它节点 `N2 ~ N5` 发送查询请求，询问其负载状态
- 根据 `N2 ~ N5` 的负载状态, `N1` 决定将 `F0` 转发到 `N2` 节点
- `N1` 连接 `N2`，插入数据 `F0`
  - 对 `N2` 来说，`N1` 为 `client`
  - `N1` 向 `N2` 插入数据与前述的 `插入流程` 完全一致
- `N2` 向 `N1` 返回结果，表明插入成功
- `N1` 向 `client` 返回结果，表明插入成功


- 当前节点的已经没有富余内存，需要将插入数据转发到其它节点上
- 如果所有节点均没有富余内存，转发到空闲内存最多的节点上
- 转发节点并不断开与 client 节点的链接

## 删除流程

- 删除操作是所有节点广播的
- 删除操作只生成 `delete log`
- 删除操作不存在与插入操作类似的转发功能
- 数据由哪个节点插入，则由哪个节点删除
- 如果插入节点宕机，如何处理？

---

## 创建索引
- 文件由哪个节点插入，则由哪个节点负责创建索引
- 如果插入节点宕机，如何处理

---

## 复制 `replica` 流程
- 复制操作是`幂等`行为，即执行复制指令前，先检查数据是否在当前节点的内存或磁盘上
- 收到复制指令，首先从 `Milvus` 节点复制，如果拥有数据的 `Milvus` 节点全部宕机，则从 `S3` 复制

- 使用 `CAS` 的模式更新 `meta`

---

## 合并文件
- 文件由那个节点插入，则由那个节点负责合并，InsertNode

---

## `Milvus`节点重启后需要加载的数据
-

## 动态扩容量
- 动态扩容不影响已经存在文件分布，只有后续新插入的数据能够进入新增节点
- 动态扩容可以保证服务不暂停

## 静态扩容
- 静态扩容会修改文件在节点上的分布
- 静态扩容需要暂停 `Milvus-Cluster` 服务

## 动态更改 `num_replicas`
- 这个暂时未考虑清除

## 如何处理节点宕机
- `Master` 定期向 `Milvus` 节点发送心跳信号请求，节点 `N1` 连续 `time_out_on_heart_beat` 次心跳信号超时，认为节点 `N1` 宕机
- `N1` 宕机后， `Master` 需要将所有 `InsertNode` 为 `N1` 的所有 `meta` 信息用其中一个正在运行的 `ReplicaNode` 代替 